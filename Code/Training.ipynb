{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (3.5.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.22.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (0.19.2)\n",
      "Requirement already satisfied: Tensorflow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (2.7.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.7.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.16.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2022.3.25)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.43.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.13.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (4.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (3.19.4)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (13.0.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (0.23.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from Tensorflow->-r requirements.txt (line 5)) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (2.22.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (60.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (4.10.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->Tensorflow->-r requirements.txt (line 5)) (3.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet.model import *\n",
    "from unet.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Unet with EAT Data\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-175ece19ead6>:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator,steps_per_epoch=90,epochs=300,callbacks=[model_checkpoint])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1567 images belonging to 1 classes.\n",
      "Found 1567 images belonging to 1 classes.\n",
      "Epoch 1/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 129.3681 - accuracy: 0.9617 - auc: 0.8278\n",
      "Epoch 00001: loss improved from inf to 129.36810, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 34s 355ms/step - loss: 129.3681 - accuracy: 0.9617 - auc: 0.8278\n",
      "Epoch 2/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9640 - auc: 0.9184\n",
      "Epoch 00002: loss improved from 129.36810 to 0.10322, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 351ms/step - loss: 0.1032 - accuracy: 0.9640 - auc: 0.9184\n",
      "Epoch 3/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9614 - auc: 0.9109\n",
      "Epoch 00003: loss did not improve from 0.10322\n",
      "90/90 [==============================] - 28s 317ms/step - loss: 0.1179 - accuracy: 0.9614 - auc: 0.9109\n",
      "Epoch 4/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9631 - auc: 0.9128\n",
      "Epoch 00004: loss did not improve from 0.10322\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.1254 - accuracy: 0.9631 - auc: 0.9128\n",
      "Epoch 5/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9612 - auc: 0.9434\n",
      "Epoch 00005: loss improved from 0.10322 to 0.09641, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 359ms/step - loss: 0.0964 - accuracy: 0.9612 - auc: 0.9434\n",
      "Epoch 6/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9651 - auc: 0.9469\n",
      "Epoch 00006: loss improved from 0.09641 to 0.08802, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 356ms/step - loss: 0.0880 - accuracy: 0.9651 - auc: 0.9469\n",
      "Epoch 7/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9615 - auc: 0.9734\n",
      "Epoch 00007: loss improved from 0.08802 to 0.06976, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 31s 350ms/step - loss: 0.0698 - accuracy: 0.9615 - auc: 0.9734\n",
      "Epoch 8/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9629 - auc: 0.9785\n",
      "Epoch 00008: loss improved from 0.06976 to 0.06318, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 357ms/step - loss: 0.0632 - accuracy: 0.9629 - auc: 0.9785\n",
      "Epoch 9/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9673 - auc: 0.9858\n",
      "Epoch 00009: loss improved from 0.06318 to 0.05577, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 357ms/step - loss: 0.0558 - accuracy: 0.9673 - auc: 0.9858\n",
      "Epoch 10/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9818 - auc: 0.9886\n",
      "Epoch 00010: loss improved from 0.05577 to 0.04914, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 351ms/step - loss: 0.0491 - accuracy: 0.9818 - auc: 0.9886\n",
      "Epoch 11/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9800 - auc: 0.9876\n",
      "Epoch 00011: loss did not improve from 0.04914\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0520 - accuracy: 0.9800 - auc: 0.9876\n",
      "Epoch 12/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9832 - auc: 0.9909\n",
      "Epoch 00012: loss improved from 0.04914 to 0.04569, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 351ms/step - loss: 0.0457 - accuracy: 0.9832 - auc: 0.9909\n",
      "Epoch 13/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9828 - auc: 0.9901\n",
      "Epoch 00013: loss did not improve from 0.04569\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0460 - accuracy: 0.9828 - auc: 0.9901\n",
      "Epoch 14/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9842 - auc: 0.9915\n",
      "Epoch 00014: loss improved from 0.04569 to 0.04262, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0426 - accuracy: 0.9842 - auc: 0.9915\n",
      "Epoch 15/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9855 - auc: 0.9927\n",
      "Epoch 00015: loss improved from 0.04262 to 0.04073, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0407 - accuracy: 0.9855 - auc: 0.9927\n",
      "Epoch 16/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9859 - auc: 0.9929\n",
      "Epoch 00016: loss improved from 0.04073 to 0.04061, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0406 - accuracy: 0.9859 - auc: 0.9929\n",
      "Epoch 17/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9874 - auc: 0.9939\n",
      "Epoch 00017: loss improved from 0.04061 to 0.03681, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0368 - accuracy: 0.9874 - auc: 0.9939\n",
      "Epoch 18/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9882 - auc: 0.9945\n",
      "Epoch 00018: loss did not improve from 0.03681\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0375 - accuracy: 0.9882 - auc: 0.9945\n",
      "Epoch 19/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9876 - auc: 0.9942\n",
      "Epoch 00019: loss improved from 0.03681 to 0.03571, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 356ms/step - loss: 0.0357 - accuracy: 0.9876 - auc: 0.9942\n",
      "Epoch 20/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9899 - auc: 0.9954\n",
      "Epoch 00020: loss improved from 0.03571 to 0.03258, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0326 - accuracy: 0.9899 - auc: 0.9954\n",
      "Epoch 21/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9895 - auc: 0.9956\n",
      "Epoch 00021: loss improved from 0.03258 to 0.03244, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0324 - accuracy: 0.9895 - auc: 0.9956\n",
      "Epoch 22/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9901 - auc: 0.9958\n",
      "Epoch 00022: loss improved from 0.03244 to 0.03217, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0322 - accuracy: 0.9901 - auc: 0.9958\n",
      "Epoch 23/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9907 - auc: 0.9960\n",
      "Epoch 00023: loss improved from 0.03217 to 0.03071, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 358ms/step - loss: 0.0307 - accuracy: 0.9907 - auc: 0.9960\n",
      "Epoch 24/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9905 - auc: 0.9958\n",
      "Epoch 00024: loss improved from 0.03071 to 0.03070, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 356ms/step - loss: 0.0307 - accuracy: 0.9905 - auc: 0.9958\n",
      "Epoch 25/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9899 - auc: 0.9953\n",
      "Epoch 00025: loss did not improve from 0.03070\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0315 - accuracy: 0.9899 - auc: 0.9953\n",
      "Epoch 26/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9917 - auc: 0.9968\n",
      "Epoch 00026: loss improved from 0.03070 to 0.02808, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 351ms/step - loss: 0.0281 - accuracy: 0.9917 - auc: 0.9968\n",
      "Epoch 27/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9932 - auc: 0.9970\n",
      "Epoch 00027: loss improved from 0.02808 to 0.02569, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 355ms/step - loss: 0.0257 - accuracy: 0.9932 - auc: 0.9970\n",
      "Epoch 28/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9928 - auc: 0.9973\n",
      "Epoch 00028: loss improved from 0.02569 to 0.02552, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 358ms/step - loss: 0.0255 - accuracy: 0.9928 - auc: 0.9973\n",
      "Epoch 29/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9926 - auc: 0.9970\n",
      "Epoch 00029: loss improved from 0.02552 to 0.02548, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 352ms/step - loss: 0.0255 - accuracy: 0.9926 - auc: 0.9970\n",
      "Epoch 30/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9931 - auc: 0.9967\n",
      "Epoch 00030: loss improved from 0.02548 to 0.02536, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0254 - accuracy: 0.9931 - auc: 0.9967\n",
      "Epoch 31/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9934 - auc: 0.9970\n",
      "Epoch 00031: loss improved from 0.02536 to 0.02387, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 352ms/step - loss: 0.0239 - accuracy: 0.9934 - auc: 0.9970\n",
      "Epoch 32/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9932 - auc: 0.9972\n",
      "Epoch 00032: loss did not improve from 0.02387\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0243 - accuracy: 0.9932 - auc: 0.9972\n",
      "Epoch 33/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9939 - auc: 0.9974\n",
      "Epoch 00033: loss improved from 0.02387 to 0.02204, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 357ms/step - loss: 0.0220 - accuracy: 0.9939 - auc: 0.9974\n",
      "Epoch 34/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9935 - auc: 0.9977\n",
      "Epoch 00034: loss did not improve from 0.02204\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0221 - accuracy: 0.9935 - auc: 0.9977\n",
      "Epoch 35/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9938 - auc: 0.9978\n",
      "Epoch 00035: loss improved from 0.02204 to 0.02131, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0213 - accuracy: 0.9938 - auc: 0.9978\n",
      "Epoch 36/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9936 - auc: 0.9973\n",
      "Epoch 00036: loss did not improve from 0.02131\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0219 - accuracy: 0.9936 - auc: 0.9973\n",
      "Epoch 37/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9935 - auc: 0.9971\n",
      "Epoch 00037: loss did not improve from 0.02131\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0222 - accuracy: 0.9935 - auc: 0.9971\n",
      "Epoch 38/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9941 - auc: 0.9978\n",
      "Epoch 00038: loss improved from 0.02131 to 0.02037, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 360ms/step - loss: 0.0204 - accuracy: 0.9941 - auc: 0.9978\n",
      "Epoch 39/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9950 - auc: 0.9978\n",
      "Epoch 00039: loss improved from 0.02037 to 0.01809, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 31s 348ms/step - loss: 0.0181 - accuracy: 0.9950 - auc: 0.9978\n",
      "Epoch 40/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9946 - auc: 0.9982\n",
      "Epoch 00040: loss did not improve from 0.01809\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0186 - accuracy: 0.9946 - auc: 0.9982\n",
      "Epoch 41/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9933 - auc: 0.9960\n",
      "Epoch 00041: loss did not improve from 0.01809\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0224 - accuracy: 0.9933 - auc: 0.9960\n",
      "Epoch 42/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9931 - auc: 0.9972\n",
      "Epoch 00042: loss did not improve from 0.01809\n",
      "90/90 [==============================] - 28s 316ms/step - loss: 0.0220 - accuracy: 0.9931 - auc: 0.9972\n",
      "Epoch 43/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9939 - auc: 0.9973\n",
      "Epoch 00043: loss did not improve from 0.01809\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0199 - accuracy: 0.9939 - auc: 0.9973\n",
      "Epoch 44/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9946 - auc: 0.9984\n",
      "Epoch 00044: loss did not improve from 0.01809\n",
      "90/90 [==============================] - 28s 316ms/step - loss: 0.0181 - accuracy: 0.9946 - auc: 0.9984\n",
      "Epoch 45/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9949 - auc: 0.9983\n",
      "Epoch 00045: loss improved from 0.01809 to 0.01678, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 352ms/step - loss: 0.0168 - accuracy: 0.9949 - auc: 0.9983\n",
      "Epoch 46/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9942 - auc: 0.9980\n",
      "Epoch 00046: loss did not improve from 0.01678\n",
      "90/90 [==============================] - 29s 316ms/step - loss: 0.0182 - accuracy: 0.9942 - auc: 0.9980\n",
      "Epoch 47/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9947 - auc: 0.9987\n",
      "Epoch 00047: loss did not improve from 0.01678\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0168 - accuracy: 0.9947 - auc: 0.9987\n",
      "Epoch 48/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9953 - auc: 0.9982\n",
      "Epoch 00048: loss improved from 0.01678 to 0.01575, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 359ms/step - loss: 0.0158 - accuracy: 0.9953 - auc: 0.9982\n",
      "Epoch 49/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9946 - auc: 0.9983\n",
      "Epoch 00049: loss did not improve from 0.01575\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0168 - accuracy: 0.9946 - auc: 0.9983\n",
      "Epoch 50/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952 - auc: 0.9987\n",
      "Epoch 00050: loss improved from 0.01575 to 0.01536, saving model to unet_EAT.hdf5\n",
      "90/90 [==============================] - 32s 354ms/step - loss: 0.0154 - accuracy: 0.9952 - auc: 0.9987\n",
      "Epoch 51/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9951 - auc: 0.9979\n",
      "Epoch 00051: loss did not improve from 0.01536\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0157 - accuracy: 0.9951 - auc: 0.9979\n",
      "Epoch 52/300\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9951 - auc: 0.9987\n",
      "Epoch 00052: loss did not improve from 0.01536\n",
      "90/90 [==============================] - 29s 317ms/step - loss: 0.0154 - accuracy: 0.9951 - auc: 0.9987\n",
      "Epoch 53/300\n",
      "42/90 [=============>................] - ETA: 15s - loss: 0.0158 - accuracy: 0.9946 - auc: 0.9987"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/461-EAT-Project/Code/Training.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f646f6d696e697175656672616e736f6e2f4465736b746f702f3436312d4541542d50726f6a656374/workspaces/461-EAT-Project/Code/Training.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m unet()\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f646f6d696e697175656672616e736f6e2f4465736b746f702f3436312d4541542d50726f6a656374/workspaces/461-EAT-Project/Code/Training.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39munet_EAT.hdf5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f646f6d696e697175656672616e736f6e2f4465736b746f702f3436312d4541542d50726f6a656374/workspaces/461-EAT-Project/Code/Training.ipynb#ch0000004vscode-remote?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit_generator(generator,steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m90\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[model_checkpoint])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2016\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2004'>2005</a>\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2005'>2006</a>\u001b[0m \n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2006'>2007</a>\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2007'>2008</a>\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2008'>2009</a>\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2009'>2010</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2010'>2011</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2011'>2012</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2012'>2013</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2013'>2014</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2014'>2015</a>\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2015'>2016</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2016'>2017</a>\u001b[0m     generator,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2017'>2018</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2018'>2019</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2019'>2020</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2020'>2021</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2021'>2022</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2022'>2023</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2023'>2024</a>\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2024'>2025</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2025'>2026</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2026'>2027</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2027'>2028</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2028'>2029</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=2029'>2030</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1221\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=1218'>1219</a>\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=1219'>1220</a>\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=1220'>1221</a>\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=1221'>1222</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/engine/training.py?line=1222'>1223</a>\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=428'>429</a>\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=429'>430</a>\u001b[0m \n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=430'>431</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=431'>432</a>\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=432'>433</a>\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=433'>434</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=434'>435</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=435'>436</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=292'>293</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=293'>294</a>\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=294'>295</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=295'>296</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=296'>297</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=297'>298</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=312'>313</a>\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=313'>314</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=315'>316</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=317'>318</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=318'>319</a>\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:354\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=351'>352</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=352'>353</a>\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=353'>354</a>\u001b[0m   hook(batch, logs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=355'>356</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=356'>357</a>\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1032\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1030'>1031</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1031'>1032</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1104\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1099'>1100</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1101'>1102</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1102'>1103</a>\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1103'>1104</a>\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/keras/callbacks.py?line=1104'>1105</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:554\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=550'>551</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=551'>552</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=553'>554</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=864'>865</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=865'>866</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=867'>868</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=868'>869</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=869'>870</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=864'>865</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=865'>866</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=867'>868</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=868'>869</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py?line=869'>870</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:550\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=547'>548</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=548'>549</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=549'>550</a>\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=550'>551</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py?line=551'>552</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1125'>1126</a>\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1126'>1127</a>\u001b[0m \n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1127'>1128</a>\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1145'>1146</a>\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1146'>1147</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1147'>1148</a>\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1148'>1149</a>\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1149'>1150</a>\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1112'>1113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1113'>1114</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1114'>1115</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1115'>1116</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py?line=1116'>1117</a>\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "generator = trainGenerator(8,'../Training Data','AllImages','AllMasks',data_gen_args,save_to_dir = None, image_color_mode = 'rgb')\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_EAT.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(generator,steps_per_epoch=90,epochs=300,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-cc6db0cafe29>:24: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  results = model.predict_generator(gen,verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774/774 [==============================] - 36s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "def generateTestsFromPath(test_path, target_size = (256,256)):\n",
    "    images = os.listdir(test_path)\n",
    "    for i in images:\n",
    "        img = io.imread(test_path +\"/\" +i, as_gray = False)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img,(256,256))\n",
    "        img = img[:,:,0:3]\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "def saveResults(results,save_path):\n",
    "    shape = results.shape\n",
    "    for i in range(0,shape[0]):\n",
    "        result = results[i,:,:,0] * ((2**8)-1)\n",
    "        resultRGB = np.zeros((shape[1],shape[2],3))\n",
    "        resultRGB[:,:,0] = result\n",
    "        resultRGB[:,:,1] = result\n",
    "        resultRGB[:,:,2] = result\n",
    "        matplotlib.image.imsave(os.path.join(save_path,\"%d_predict.png\"%i), resultRGB.astype(np.uint8))\n",
    "\n",
    "gen = generateTestsFromPath(\"../Test Data/AllImages\")\n",
    "model = unet()\n",
    "model.load_weights(\"unet_EAT.hdf5\")\n",
    "results = model.predict_generator(gen,verbose=1)\n",
    "saveResults(results, \"../Test Data/AllMasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = results.shape\n",
    "result = results[0,:,:,0] * ((2**8)-1)\n",
    "resultRGB = np.zeros((shape[1],shape[2],3))\n",
    "resultRGB[:,:,0] = result\n",
    "resultRGB[:,:,1] = result\n",
    "resultRGB[:,:,2] = result\n",
    "resultRGB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import skimage.io as io\n",
    "\n",
    "model = unet()\n",
    "model.load_weights(\"unet_EAT.hdf5\")\n",
    "test_path = \"../Test Data/AllImages/15.png\"\n",
    "\n",
    "img = io.imread(test_path,as_gray = False)\n",
    "img = img / 255\n",
    "img = trans.resize(img,(256,256))\n",
    "img = img[:,:,0:3]\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "result = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/461-EAT-Project/Code/Training.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f646f6d696e697175656672616e736f6e2f4465736b746f702f3436312d4541542d50726f6a656374/workspaces/461-EAT-Project/Code/Training.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(result[\u001b[39m0\u001b[39;49m,:,:,\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f646f6d696e697175656672616e736f6e2f4465736b746f702f3436312d4541542d50726f6a656374/workspaces/461-EAT-Project/Code/Training.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 4 were indexed"
     ]
    }
   ],
   "source": [
    "plt.imshow(result[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
